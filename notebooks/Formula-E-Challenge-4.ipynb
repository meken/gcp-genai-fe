{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "provenance": [],
      "name": "Formula_E_Challenge_2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Challenge 4: Telemetry to the Rescue"
      ],
      "metadata": {
        "id": "VI0xLxmm7HBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find accident in telemetry data"
      ],
      "metadata": {
        "id": "BUUj-wyRc5za"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You need to desing a SQL query that returns the `car_number`, `driver_name` and the average `brake` & `speed` for the full second just before the accident. You should have the timestamp of the accident from the previous challenge.\n",
        "\n",
        "Keep in mind that the timesamp is in local time, whereas the telemetry data uses UTC."
      ],
      "metadata": {
        "id": "VZYkXrwW-24E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the accident in telemetry data that is loaded into BQ\n",
        "%%bigquery telemetry_during_accident\n",
        "-- TODO a SQL query that aggregates the brake and speed data for the second just before the accident"
      ],
      "metadata": {
        "id": "6mxgerm8F6nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find the drivers"
      ],
      "metadata": {
        "id": "Op9epADFsn5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have the filtered & aggregated data, let's ask Gemini to tell us which two drivers were involved in the accident.\n",
        "\n",
        "Design a prompt that determines **which drivers** were involved and **why the model thinks that**.\n",
        "\n",
        "Note that we're *appending the result of the query from the previous cell to your prompt*, so you can refer to that."
      ],
      "metadata": {
        "id": "0067gn0l_ZuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "TODO a prompt that asks Gemini to analyze the outcome of the SQL query\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "sTynac1B67aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel\n",
        "\n",
        "\n",
        "shell_output = ! gcloud config list project --format 'value(core.project)' 2>/dev/null\n",
        "PROJECT_ID = shell_output[0]\n",
        "REGION = \"us-central1\"\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)\n",
        "model = GenerativeModel(\"gemini-2.0-flash\")\n",
        "response = model.generate_content([prompt, telemetry_during_accident.to_markdown()])\n",
        "\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "id": "kc1-lRve4Qu0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}